{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification using the one-dimensional Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Wine** data set is the running example for our discussion of the *generative approach to classification*. \n",
    "\n",
    "The data can be downloaded from the UCI repository (https://archive.ics.uci.edu/ml/datasets/wine). It contains 178 labeled data points, each corresponding to a bottle of wine:\n",
    "* The features (`x`): a 13-dimensional vector consisting of visual and chemical features for the bottle of wine\n",
    "* The label (`y`): the winery from which the bottle came (1,2,3)\n",
    "\n",
    "Before continuing, download the data set and place it in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "# installing packages for interactive graphs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the Wine data set. There are 178 data points, each with 13 features and a label (1,2,3).\n",
    "We will divide these into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wine.data.txt' needs to be in the same directory\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a particular \"random\" permutation of the data, and use these to effect the training / test split.\n",
    "We get four arrays:\n",
    "* `trainx`: 130x13, the training points\n",
    "* `trainy`: 130x1, labels of the training points\n",
    "* `testx`: 48x13, the test points\n",
    "* `testy`: 48x1, labels of the test points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "# Also split apart data and labels\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many training points there are from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 54, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainy==1), sum(trainy==2), sum(trainy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you figure out how many test points there are from each class? *Note down these three numbers: you will enter it as part of this week's programming assignment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 17, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify this cell\n",
    "sum(testy==1), sum(testy==2), sum(testy==3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Look at the distribution of a single feature from one of the wineries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick just one feature: 'Alcohol'. This is the first feature, that is, number 0. Here is a *histogram* of this feature's values under class 1, along with the *Gaussian fit* to this distribution.\n",
    "\n",
    "<img src=\"histogram.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm: how can we generate a figure like this? \n",
    "\n",
    "The following function, **density_plot**, does this for any feature and label. The first line adds an interactive component that lets you choose these parameters using sliders. \n",
    "\n",
    "<font color=\"magenta\">Try it out!</font> And then, look at the code carefully to understand exactly what it is doing, line by line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd4e5f17783497fa212245b7e4b3870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0wLCBkZXNjcmlwdGlvbj11J2ZlYXR1cmUnLCBtYXg9MTIpLCBJbnRTbGlkZXIodmFsdWU9MSwgZGVzY3JpcHRpb249dSdsYWLigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12), label=IntSlider(1,1,3))\n",
    "def density_plot(feature, label):\n",
    "    plt.hist(trainx[trainy==label,feature], normed=True)\n",
    "    #\n",
    "    mu = np.mean(trainx[trainy==label,feature]) # mean\n",
    "    var = np.var(trainx[trainy==label,feature]) # variance\n",
    "    std = np.sqrt(var) # standard deviation\n",
    "    #\n",
    "    x_axis = np.linspace(mu - 3*std, mu + 3*std, 1000)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mu,std), 'r', lw=2)\n",
    "    plt.title(\"Winery \"+str(label) )\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.02020202, 2.02020202, 3.03030303, 3.03030303, 0.50505051,\n",
       "        1.51515152, 1.01010101, 1.01010101, 1.01010101, 1.51515152]),\n",
       " array([2.15, 2.21, 2.27, 2.33, 2.39, 2.45, 2.51, 2.57, 2.63, 2.69, 2.75]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(trainx[trainy==3,2], normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 3., 2., 1., 2., 2., 1., 3., 2., 2., 3., 3., 1., 2., 3., 2., 1.,\n",
       "       1., 2., 1., 2., 1., 1., 2., 2., 2., 2., 2., 2., 3., 1., 1., 2., 1.,\n",
       "       1., 1., 3., 2., 2., 3., 1., 1., 2., 2., 2., 1., 3., 2., 3., 1., 3.,\n",
       "       3., 1., 3., 1., 2., 3., 3., 2., 3., 3., 1., 2., 3., 2., 2., 3., 2.,\n",
       "       1., 2., 2., 2., 1., 1., 2., 2., 3., 3., 2., 2., 2., 3., 3., 1., 3.,\n",
       "       2., 2., 2., 2., 2., 1., 1., 2., 1., 3., 1., 3., 1., 1., 2., 1., 2.,\n",
       "       2., 1., 3., 2., 1., 2., 2., 2., 3., 1., 3., 3., 1., 1., 2., 3., 1.,\n",
       "       1., 2., 2., 1., 1., 1., 3., 2., 1., 2., 3.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False, False, False, False,  True, False,\n",
       "       False,  True,  True, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False,  True, False,  True, False,  True,  True, False,  True,\n",
       "       False, False,  True,  True, False,  True,  True, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "        True, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False,  True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy==3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the function **density_plot**, the code for plotting the Gaussian density focuses on the region within 3 standard deviations of the mean. Do you see where this happens? Why do you think we make this choice?\n",
    "\n",
    "Here's something for you to figure out: for which feature (0-12) does the distribution of (training set) values for winery 1 have the *smallest* standard deviation? Write down the answer: you will need to enter it as part of this week's programming assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modify this cell\n",
    "std = np.zeros(13)\n",
    "for feature in range(0,13):\n",
    "    std[feature] = np.std(trainx[trainy==1,feature])\n",
    "std\n",
    "feature_min=np.argmin(std)\n",
    "feature_min\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit a Gaussian to each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that will fit a Gaussian generative model to the three classes, restricted to just a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes y takes on values 1,2,3\n",
    "# this function is used to extract all #1 label wine and calculate mean and standard deviatuion to build up norm distribution\n",
    "def fit_generative_model(x,y,feature):\n",
    "    k = 3 # number of classes\n",
    "    mu = np.zeros(k+1) # list of means\n",
    "    var = np.zeros(k+1) # list of variances\n",
    "    pi = np.zeros(k+1) # list of class weights\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y==label)\n",
    "        mu[label] = np.mean(x[indices,feature])\n",
    "        var[label] = np.var(x[indices,feature])\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, var, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call this function on the feature 'alcohol'. What are the class weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33076923  0.41538462  0.25384615]\n"
     ]
    }
   ],
   "source": [
    "feature = 0 # 'alcohol'\n",
    "mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "print pi[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, display the Gaussian distribution for each of the three classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ed6bba44b74903b7b2602e440182c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0wLCBkZXNjcmlwdGlvbj11J2ZlYXR1cmUnLCBtYXg9MTIpLCBCdXR0b24oZGVzY3JpcHRpb249dSdSdW4gSW50ZXJhY3QnLCDigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual( feature=IntSlider(0,0,12) )\n",
    "def show_densities(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "    colors = ['r', 'k', 'g']\n",
    "    for label in range(1,4):\n",
    "        m = mu[label]\n",
    "        s = np.sqrt(var[label])\n",
    "        x_axis = np.linspace(m - 3*s, m+3*s, 1000)\n",
    "        plt.plot(x_axis, norm.pdf(x_axis,m,s), colors[label-1], label=\"class \" + str(label))\n",
    "    plt.xlabel(featurenames[feature], fontsize=14, color='red')\n",
    "    plt.ylabel('Density', fontsize=14, color='red')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the widget above to look at the three class densities for each of the 13 features. Here are some questions for you:\n",
    "* For which feature (0-12) do the densities for classes 1 and 3 *overlap* the most?\n",
    "* For which feature (0-12) is class 3 the most spread out relative to the other two classes?\n",
    "* For which feature (0-12) do the three classes seem the most *separated* (this is somewhat subjective at present)?\n",
    "\n",
    "*Write down the answers to these questions: you will enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict labels for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well can we predict the class (1,2,3) based just on one feature? The code below lets us find this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab0147813a94d48bec1674c3eb9deab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0wLCBkZXNjcmlwdGlvbj11J2ZlYXR1cmUnLCBtYXg9MTIpLCBPdXRwdXQoKSksIF9kb21fY2xhc3Nlcz0odSd3aWRnZXQtaW7igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( feature=IntSlider(0,0,12) )\n",
    "def test_model(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "\n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    n_test = len(testy) # Number of test points\n",
    "    score = np.zeros((n_test,k+1))\n",
    "    for i in range(0,n_test):\n",
    "        for label in range(1,k+1):\n",
    "            # this formular is log(pi(j)*Pj(x))\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(testx[i,feature], mu[label], np.sqrt(var[label])) # to find the possibility of textx(i,feature) in norm\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != testy)\n",
    "    #print \"Test error using feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(n_test)\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8291396ef1940f691befbebea1e3586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0wLCBkZXNjcmlwdGlvbj11J2ZlYXR1cmUnLCBtYXg9MTIpLCBPdXRwdXQoKSksIF9kb21fY2xhc3Nlcz0odSd3aWRnZXQtaW7igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact( feature=IntSlider(0,0,12) )\n",
    "def train_model(feature):\n",
    "    mu, var, pi = fit_generative_model(trainx, trainy, feature)\n",
    "\n",
    "    k = 3 # Labels 1,2,...,k\n",
    "    n_train = len(trainy) # Number of test points\n",
    "    score = np.zeros((n_train,k+1))\n",
    "    for i in range(0,n_train):\n",
    "        for label in range(1,k+1):\n",
    "            # this formular is log(pi(j)*Pj(x))\n",
    "            score[i,label] = np.log(pi[label]) + \\\n",
    "            norm.logpdf(trainx[i,feature], mu[label], np.sqrt(var[label])) # to find the possibility of textx(i,feature) in norm\n",
    "    predictions = np.argmax(score[:,1:4], axis=1) + 1\n",
    "    # Finally, tally up score\n",
    "    errors_train = np.sum(predictions != trainy)\n",
    "    #print \"Test error using feature \" + featurenames[feature] + \": \" + str(errors) + \"/\" + str(n_test)\n",
    "    return errors_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">One last exercise</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are looking at classifiers that use just one out of a possible 13 features. Choosing a subset of features is called **feature selection**. In general, this is something we would need to do based solely on the *training set*--that is, without peeking at the *test set*.\n",
    "\n",
    "For the wine data, compute the training error and test error associated with each choice of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your code here\n",
    "error_test=np.zeros(feature+1)\n",
    "error_train=np.zeros(feature+1)\n",
    "for i in range (0,feature+1):\n",
    "    error_test[i]=test_model (i)\n",
    "    error_train[i]=train_model(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17. 23. 29. 23. 21. 16.  8. 23. 16. 10. 14. 19. 17.]\n",
      "[44. 49. 66. 68. 61. 46. 27. 55. 60. 38. 48. 47. 35.]\n"
     ]
    }
   ],
   "source": [
    "print error_test\n",
    "print error_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your findings, answer the following questions:\n",
    "* Which three features have the lowest training error? List them in order (best first).\n",
    "* Which three features have the lowest test error? List them in order (best first).\n",
    "\n",
    "*Note down your answers: you will enter them later, as part of this week's programming assignment*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
